{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DenseAV Demonstration Notebook\n",
    "\n",
    "> ⚠️ Change your collab runtime to T4 GPU before running this notebook\n",
    "\n",
    "In this notebook we will walk through how to load, visualize, and work with our catalog of pre-trained models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c413e5bb192c72eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up Google Collab\n",
    "> ⚠️ Skip this section if you are not on Google Collab\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c65e267ad0b57b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!git clone https://github.com/mhamilton723/DenseAV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e0c798342f1699"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"DenseAV/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "397cf48fa3832a2b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:03:20.413866Z",
     "start_time": "2024-06-06T17:03:20.296186Z"
    }
   },
   "id": "19d3129b03459c94",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies and load a pretrained DenseAV Model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800b72c026c98194"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:07:27.801018Z",
     "start_time": "2024-06-06T17:07:24.055483Z"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchaudio.functional import resample\n",
    "\n",
    "from denseav.plotting import plot_attention_video, plot_2head_attention_video, plot_feature_video\n",
    "from denseav.shared import norm, crop_to_divisor, blur_dim"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name = \"sound_and_language\"\n",
    "video_path = \"samples/puppies.mp4\"\n",
    "result_dir = \"results\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:07:27.806669Z",
     "start_time": "2024-06-06T17:07:27.803188Z"
    }
   },
   "id": "e0de70a3865c7239",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/marhamil/.cache/torch/hub/mhamilton723_DenseAV_main\n",
      "2024-06-06 17:07:29.759719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-06 17:07:29.759793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-06 17:07:29.761321: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-06 17:07:29.769751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 17:07:30.778103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using cache found in /home/marhamil/.cache/torch/hub/facebookresearch_dino_main\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147,456 || all params: 21,817,728 || trainable%: 0.6758540577644016\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('mhamilton723/DenseAV', model_name).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:07:37.721422Z",
     "start_time": "2024-06-06T17:07:27.808035Z"
    }
   },
   "id": "e35605083dbeeb1d",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load a sample video and prepare it for DenseAV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "742cfc52ee8d0aad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "original_frames, audio, info = torchvision.io.read_video(video_path, pts_unit='sec')\n",
    "sample_rate = 16000\n",
    "\n",
    "if info[\"audio_fps\"] != sample_rate:\n",
    "    audio = resample(audio, info[\"audio_fps\"], sample_rate)\n",
    "audio = audio[0].unsqueeze(0)\n",
    "\n",
    "img_transform = T.Compose([\n",
    "    T.Resize(224 * 2, Image.BILINEAR),\n",
    "    lambda x: crop_to_divisor(x, 8),\n",
    "    lambda x: x.to(torch.float32) / 255,\n",
    "    norm])\n",
    "\n",
    "frames = torch.cat([img_transform(f.permute(2, 0, 1)).unsqueeze(0) for f in original_frames], axis=0)\n",
    "\n",
    "plotting_img_transform = T.Compose([\n",
    "    T.Resize(224 * 4, Image.BILINEAR),\n",
    "    lambda x: crop_to_divisor(x, 8),\n",
    "    lambda x: x.to(torch.float32) / 255])\n",
    "\n",
    "frames_to_plot = plotting_img_transform(original_frames.permute(0, 3, 1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:07:40.993012Z",
     "start_time": "2024-06-06T17:07:37.724341Z"
    }
   },
   "id": "2d5b8553fc0e372",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use DenseAV to obtain dense AV-aligned features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "203ebe0f66dde1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([181, 2, 28, 28, 33])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    audio_feats = model.forward_audio({\"audio\": audio.cuda()})\n",
    "    image_feats = model.forward_image({\"frames\": frames.unsqueeze(0).cuda()}, max_batch_size=2)\n",
    "\n",
    "    sim_by_head = model.sim_agg.get_pairwise_sims(\n",
    "        {**image_feats, **audio_feats},\n",
    "        raw=False,\n",
    "        agg_sim=False,\n",
    "        agg_heads=False\n",
    "    ).mean(dim=-2).cpu()\n",
    "\n",
    "    sim_by_head = blur_dim(sim_by_head, window=3, dim=-1)\n",
    "    print(sim_by_head.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:07:51.348730Z",
     "start_time": "2024-06-06T17:07:40.995122Z"
    }
   },
   "id": "a26feec6533ad7ec",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize Cross-Modal Attention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "719b17171b1d9703"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video results/attention/sound_and_language/puppies.mp4.\n",
      "MoviePy - Writing audio in puppiesTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/attention/sound_and_language/puppies.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/attention/sound_and_language/puppies.mp4\n"
     ]
    }
   ],
   "source": [
    "plot_attention_video(\n",
    "    sim_by_head,\n",
    "    frames_to_plot,\n",
    "    audio,\n",
    "    info[\"video_fps\"],\n",
    "    sample_rate,\n",
    "    join(result_dir, \"attention\", model_name, f'{video_path.split(\"/\")[-1]}'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:08:03.781030Z",
     "start_time": "2024-06-06T17:07:51.350768Z"
    }
   },
   "id": "99c46e5f3a50de3c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize Cross Modal Attention by Head to Disentangle Sound and Language"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3f4d96cce322692"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video results/attention/sound_and_language/2head_puppies.mp4.\n",
      "MoviePy - Writing audio in 2head_puppiesTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/attention/sound_and_language/2head_puppies.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/attention/sound_and_language/2head_puppies.mp4\n"
     ]
    }
   ],
   "source": [
    "plot_2head_attention_video(\n",
    "    sim_by_head,\n",
    "    frames_to_plot,\n",
    "    audio,\n",
    "    info[\"video_fps\"],\n",
    "    sample_rate,\n",
    "    join(result_dir, \"attention\", model_name, f'2head_{video_path.split(\"/\")[-1]}'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:08:21.087052Z",
     "start_time": "2024-06-06T17:08:03.782840Z"
    }
   },
   "id": "91d0eec42a35de9b",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Deep Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a886cfeaf91e0ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video results/features/sound_and_language/visual_puppies.mp4.\n",
      "MoviePy - Writing audio in visual_puppiesTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/features/sound_and_language/visual_puppies.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/features/sound_and_language/visual_puppies.mp4\n",
      "Moviepy - Building video results/features/sound_and_language/audio_puppies.mp4.\n",
      "MoviePy - Writing audio in audio_puppiesTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/features/sound_and_language/audio_puppies.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/features/sound_and_language/audio_puppies.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "plot_feature_video(\n",
    "    image_feats[\"image_feats\"].cpu(),\n",
    "    audio_feats['audio_feats'].cpu(),\n",
    "    frames_to_plot,\n",
    "    audio,\n",
    "    info[\"video_fps\"],\n",
    "    sample_rate,\n",
    "    join(result_dir, \"features\", model_name, f'visual_{video_path.split(\"/\")[-1]}'),\n",
    "    join(result_dir, \"features\", model_name, f'audio_{video_path.split(\"/\")[-1]}')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T17:08:30.187416Z",
     "start_time": "2024-06-06T17:08:21.090287Z"
    }
   },
   "id": "d244fec7aaa340cd",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4acd69bab06b1f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
